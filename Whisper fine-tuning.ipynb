{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T02:12:37.235795Z",
     "iopub.status.busy": "2024-08-05T02:12:37.235441Z",
     "iopub.status.idle": "2024-08-05T03:19:52.544548Z",
     "shell.execute_reply": "2024-08-05T03:19:52.543216Z",
     "shell.execute_reply.started": "2024-08-05T02:12:37.235765Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa82566708e4dd3bc2973ce72181c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b20ad5664f845a48563e26c26683e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf9234d34c344e49b80fea1b4a79475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f80a60ff2489438e9211f8dfb4b7e1b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4082ece723d4faf88e9efae9578e205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe019c3b9334a6ebb8a3e831ecf6d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0cd63dc7def4aa886697333a3210e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb8a133e3564b10970af6de325a8535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "306070d6bda647a5a230f9888c6f1a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cde88e5d7d144e9bfe1109699a2d00d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69915c3ff30f43688668eeb372c44031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/3.87k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221a6dc822ea4c9c83cd6f12252f57d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3465 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 02:13:29.443538: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-05 02:13:29.443547: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-05 02:13:29.443530: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-05 02:13:29.443545: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-05 02:13:29.443624: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-05 02:13:29.443657: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-05 02:13:29.443687: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-05 02:13:29.443694: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-05 02:13:29.566123: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-05 02:13:29.566122: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-05 02:13:29.566132: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-05 02:13:29.566138: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-05 02:34:58.642828: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-05 02:34:58.642832: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-05 02:34:58.642922: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-05 02:34:58.642927: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-05 02:34:58.644391: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-05 02:34:58.644436: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-05 02:34:58.645054: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-05 02:34:58.645164: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-05 02:34:58.645373: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-05 02:34:58.646155: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-05 02:34:58.646762: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-05 02:34:58.647475: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-05 02:56:19.254402: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-05 02:56:19.254401: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-05 02:56:19.254419: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-05 02:56:19.254473: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-05 02:56:19.254478: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-05 02:56:19.254972: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-05 02:56:19.255603: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-05 02:56:19.255646: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-05 02:56:19.256762: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-05 02:56:19.257275: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-05 02:56:19.257709: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-05 02:56:19.258282: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-05 03:17:40.324709: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-05 03:17:40.324709: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-05 03:17:40.324709: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-05 03:17:40.324709: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-05 03:17:40.324785: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-05 03:17:40.324785: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-05 03:17:40.324791: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-05 03:17:40.326371: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-05 03:17:40.327120: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-05 03:17:40.327122: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-05 03:17:40.327440: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-05 03:17:40.328353: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation loss: 0.0451078276948205\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "import torch\n",
    "from torch.utils.data import Dataset as TorchDataset, DataLoader\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, TrainingArguments, AdamW, get_scheduler\n",
    "from datasets import Dataset\n",
    "import torchaudio.transforms as T\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#Load text files \n",
    "def load_dataset(root_folder):\n",
    "    text_files = {'train': [], 'test': []}\n",
    "    \n",
    "    train_folder = os.path.join(root_folder, 'TRAIN')  # data/TRAIN\n",
    "    test_folder = os.path.join(root_folder, 'TEST')    # data/TEST\n",
    "    \n",
    "    for folder in [train_folder, test_folder]:\n",
    "        subset = 'train' if 'TRAIN' in folder else 'test'\n",
    "        for DR in os.listdir(folder):\n",
    "            DR_folder = os.path.join(folder, DR)  # ex: data/TRAIN/DR1\n",
    "            if os.path.isdir(DR_folder):\n",
    "                for text in os.listdir(DR_folder):\n",
    "                    text_folder = os.path.join(DR_folder, text)  # ex: data/TRAIN/DR1/FCJF0\n",
    "                    if os.path.isdir(text_folder):\n",
    "                        for file in os.listdir(text_folder):\n",
    "                            if file.endswith('.TXT'):\n",
    "                                file_path = os.path.join(text_folder, file)  # ex: data/TRAIN/DR1/FCJF0/SA1.TXT\n",
    "                                text_files[subset].append(file_path)\n",
    "                                \n",
    "    return text_files\n",
    "\n",
    "# Load transcription data\n",
    "def load_transcription_data(txt_files):\n",
    "    data = []\n",
    "    for file_path in txt_files:\n",
    "        with open(file_path, 'r') as file:\n",
    "            transcription = file.read().strip()\n",
    "        data.append({\n",
    "            'audio_path': file_path.replace('.TXT', '.WAV'),  # Replaces .TXT with .WAV to get the audio path\n",
    "            'transcription': transcription\n",
    "        })\n",
    "    return pd.DataFrame(data) #Returns a DataFrame with audio_path and transcription\n",
    "\n",
    "\n",
    "root_folder = \"/kaggle/input/timitdataset/Dataset/data\"\n",
    "Text_files = load_dataset(root_folder)\n",
    "\n",
    "# Load and preprocess data\n",
    "train_txt_files = [path for path in Text_files['train'] if path.endswith('.TXT')]  #creates a list of file paths  that end with .TXT.\n",
    "test_txt_files = [path for path in Text_files['test'] if path.endswith('.TXT')]\n",
    "\n",
    "train_data = load_transcription_data(train_txt_files)\n",
    "test_data = load_transcription_data(test_txt_files)\n",
    "\n",
    "# Convert pandas DataFrames to Hugging Face Dataset objects\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "test_dataset = Dataset.from_pandas(test_data)\n",
    "\n",
    "\n",
    "# Whisper processor and model\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
    "\n",
    "class WhisperDataset(TorchDataset):\n",
    "    def __init__(self, data, processor, max_audio_length=3000, max_label_length=128):\n",
    "        self.data = data.to_dict('records')    #Converts the DataFrame to a list of dictionaries, each dictionary represents an audio-transcription pair.\n",
    "        self.processor = processor      # Stores the Whisper processor for feature extraction and tokenization.\n",
    "        self.max_audio_length = max_audio_length  #Maximum length for audio input (samples)\n",
    "        self.max_label_length = max_label_length  #Maximum length for labels (transcriptions)\n",
    "        self.audio_transform = T.Resample(orig_freq=16000, new_freq=16000)  # Resample if needed\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]   #Retrieves the sample at index \n",
    "        audio, _ = torchaudio.load(item['audio_path'])\n",
    "        \n",
    "        if audio.size(0) > 1:  # Ensure single channel audio\n",
    "            audio = audio.mean(dim=0, keepdim=True)\n",
    "        \n",
    "        audio = self.audio_transform(audio)\n",
    "        audio = audio.squeeze(0)  # Remove channel dimension\n",
    "\n",
    "        # Use processor for encoding\n",
    "        inputs = self.processor(audio.numpy(), return_tensors=\"pt\", sampling_rate=16000)\n",
    "\n",
    "        # Check for available keys and update accordingly\n",
    "        if 'input_features' not in inputs:\n",
    "            raise KeyError(\"Key 'input_features' not found in processor output\")\n",
    "\n",
    "        # Get the input values for the model (Extracts and reshapes the input features)\n",
    "        input_features = inputs['input_features'].squeeze(0)\n",
    "\n",
    "        # Tokenize transcription\n",
    "        labels = self.processor.tokenizer(item['transcription'], return_tensors=\"pt\").input_ids.squeeze(0)\n",
    "        \n",
    "        # Pad or truncate labels to max_label_length\n",
    "        if labels.size(0) < self.max_label_length:\n",
    "            padding = self.max_label_length - labels.size(0)\n",
    "            labels = torch.cat([labels, torch.tensor([self.processor.tokenizer.pad_token_id] * padding)])\n",
    "        elif labels.size(0) > self.max_label_length:\n",
    "            labels = labels[:self.max_label_length]\n",
    "\n",
    "        return {\n",
    "            'input_features': input_features,\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "    \n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    WhisperDataset(train_data, processor),\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=4  # Adjust based on CPU cores\n",
    ")\n",
    "\n",
    "eval_loader = DataLoader(\n",
    "    WhisperDataset(test_data, processor),\n",
    "    batch_size=4,\n",
    "    num_workers=4  # Adjust based on your CPU cores\n",
    ")\n",
    "\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\", #evaluation will be done at the end of each epoch.\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=3,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    "    report_to=[\"none\"],  # This should disable wandb\n",
    ")\n",
    "\n",
    "\n",
    "# Define optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5) #AdamW: Optimizer for weight decay and learning rate by adjusting the weights based on the gradients computed during backpropagation\n",
    "num_training_steps = training_args.num_train_epochs * len(train_loader)\n",
    "lr_scheduler = get_scheduler(  #adjusts the learning rate according to a predefined schedule\n",
    "    name=\"linear\",   #linearly increases the learning rate during the warmup phase and then decreases it.\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "progress_bar = tqdm(range(num_training_steps)) #track the number of training steps.\n",
    "\n",
    "model.train()\n",
    "\n",
    "\n",
    "for epoch in range(training_args.num_train_epochs):\n",
    "    for batch in train_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()  #Clears the gradients to avoid accumulation.\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        \n",
    "# Evaluation loop\n",
    "model.eval()\n",
    "\n",
    "eval_loss = 0\n",
    "for batch in eval_loader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "        eval_loss += outputs.loss.item()\n",
    "\n",
    "eval_loss = eval_loss / len(eval_loader)\n",
    "print(f\"Evaluation loss: {eval_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T03:20:01.880184Z",
     "iopub.status.busy": "2024-08-05T03:20:01.879289Z",
     "iopub.status.idle": "2024-08-05T03:20:16.689351Z",
     "shell.execute_reply": "2024-08-05T03:20:16.688385Z",
     "shell.execute_reply.started": "2024-08-05T03:20:01.880146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jiwer\n",
      "  Downloading jiwer-3.0.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from jiwer) (8.1.7)\n",
      "Collecting rapidfuzz<4,>=3 (from jiwer)\n",
      "  Downloading rapidfuzz-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Downloading jiwer-3.0.4-py3-none-any.whl (21 kB)\n",
      "Downloading rapidfuzz-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
      "Successfully installed jiwer-3.0.4 rapidfuzz-3.9.5\n"
     ]
    }
   ],
   "source": [
    "!pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T03:32:47.709529Z",
     "iopub.status.busy": "2024-08-05T03:32:47.708788Z",
     "iopub.status.idle": "2024-08-05T03:32:48.958094Z",
     "shell.execute_reply": "2024-08-05T03:32:48.957083Z",
     "shell.execute_reply.started": "2024-08-05T03:32:47.709498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: 0 74650 A king ruled the state in the early days, the ship was torn apart on the sharp reef. The sun is kept him home the third week. The wide road shimmered in the hot sun. The lazy cow lay in the cool grass. This is square stone over the fence. The rope will bind the seven books at once. Hop over the fence and punger, friendly gang left the drugstore. Mesh wire keeps chicks inside.\n"
     ]
    }
   ],
   "source": [
    "def transcribe_audio(audio_path, model, processor, device):\n",
    "    # Load and preprocess audio\n",
    "    audio, sample_rate = torchaudio.load(audio_path)\n",
    "#     print(f\"Loaded audio shape: {audio.shape}, Sample rate: {sample_rate}\")\n",
    "    \n",
    "    if audio.size(0) > 1:  # Ensure single channel audio\n",
    "        audio = audio.mean(dim=0, keepdim=True)\n",
    "#     print(f\"Audio shape after ensuring single channel: {audio.shape}\")\n",
    "    \n",
    "    # Resample if needed (only if original sample rate is different from 16000)\n",
    "    if sample_rate != 16000:\n",
    "        audio = T.Resample(orig_freq=sample_rate, new_freq=16000)(audio)\n",
    "    audio = audio.squeeze(0)\n",
    "#     print(f\"Audio shape after resampling: {audio.shape}\")\n",
    "\n",
    "    # Use processor for encoding\n",
    "    inputs = processor(audio.numpy(), return_tensors=\"pt\", sampling_rate=16000)\n",
    "#     print(f\"Inputs shape: {inputs['input_features'].shape}\")\n",
    "    input_features = inputs['input_features'].to(device)\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(input_features)\n",
    "#         print(f\"Generated IDs: {generated_ids}\")\n",
    "    \n",
    "    #Decodes the generated IDs into a human-readable transcription and skips any special tokens.\n",
    "    transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return transcription\n",
    "\n",
    "unseen_audio_path = \"/kaggle/input/english-audio/OSR_us_000_0014_8k.wav\"\n",
    "model.eval()\n",
    "transcription = transcribe_audio(unseen_audio_path, model, processor, device)\n",
    "print(f\"Transcription: {transcription}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Error Rate (WER)\n",
    "common metric used to evaluate the performance of speech recognition systems. It measures the differences between the reference (ground truth) transcriptions and the predicted transcriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T03:43:52.495809Z",
     "iopub.status.busy": "2024-08-05T03:43:52.495408Z",
     "iopub.status.idle": "2024-08-05T03:53:27.121843Z",
     "shell.execute_reply": "2024-08-05T03:53:27.120568Z",
     "shell.execute_reply.started": "2024-08-05T03:43:52.495772Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Error Rate (WER): 0.1760\n"
     ]
    }
   ],
   "source": [
    "from jiwer import wer\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def evaluate_wer(model, processor, test_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    for batch in tqdm(test_loader, desc=\"Evaluating\", leave=False):\n",
    "        audio_paths = batch['audio_path']\n",
    "        transcriptions = batch['transcription']\n",
    "\n",
    "        for audio_path, transcription in zip(audio_paths, transcriptions):\n",
    "            predicted_transcription = transcribe_audio(audio_path, model, processor, device)\n",
    "            predictions.append(predicted_transcription)\n",
    "            references.append(transcription)\n",
    "    \n",
    "    error = wer(references, predictions)\n",
    "    return error\n",
    "\n",
    "# Create a new DataLoader for evaluation with file paths and transcriptions\n",
    "class WhisperEvalDataset(TorchDataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data.to_dict('records')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        return {\n",
    "            'audio_path': item['audio_path'],\n",
    "            'transcription': item['transcription']\n",
    "        }\n",
    "\n",
    "eval_loader = DataLoader(\n",
    "    WhisperEvalDataset(test_data),\n",
    "    batch_size=1,  \n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "# Calculate WER on the test dataset\n",
    "error = evaluate_wer(model, processor, eval_loader, device)\n",
    "print(f\"Word Error Rate (WER): {error:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5493603,
     "sourceId": 9102619,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5495037,
     "sourceId": 9104700,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
